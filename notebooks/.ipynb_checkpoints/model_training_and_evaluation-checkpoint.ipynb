{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5f000a-28e2-4022-8b11-77469741f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "      <th>Scaled_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>-1.996823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342584</td>\n",
       "      <td>-1.996823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.158900</td>\n",
       "      <td>-1.996802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139886</td>\n",
       "      <td>-1.996802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073813</td>\n",
       "      <td>-1.996781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Class  Scaled_Amount  Scaled_Time  \n",
       "0 -0.189115  0.133558 -0.021053      0       0.244200    -1.996823  \n",
       "1  0.125895 -0.008983  0.014724      0      -0.342584    -1.996823  \n",
       "2 -0.139097 -0.055353 -0.059752      0       1.158900    -1.996802  \n",
       "3 -0.221929  0.062723  0.061458      0       0.139886    -1.996802  \n",
       "4  0.502292  0.219422  0.215153      0      -0.073813    -1.996781  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"../data/processed_creditcard.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c2a30-6d81-42aa-a001-15688abb45f7",
   "metadata": {},
   "source": [
    "Before training any model, we need to load the cleaned dataset and verify it to make sure the data is in the right format.\n",
    "\n",
    "What to Expect?\n",
    "The dataset should not have missing values.\n",
    "The dataset should be numerical (no categorical columns).\n",
    "The target column (Class) should contain:\n",
    "0 → Normal Transactions\n",
    "1 → Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4920b9-f20b-42aa-9f03-498854d3665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['Class'])  # Features\n",
    "y = df['Class']  # Target variable\n",
    "\n",
    "# Split the dataset into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150e4c4-bf27-425d-85ee-74ed54a51258",
   "metadata": {},
   "source": [
    "We split the dataset into two parts:\n",
    "\n",
    "Training Set (80%) → Used to train the model.\n",
    "Test Set (20%) → Used to evaluate how well the model performs on unseen data.\n",
    "This helps us measure generalization, ensuring the model works well on new data.\n",
    "\n",
    "What's the objective?\n",
    "X_train: Features for training (80% of data)\n",
    "X_test: Features for testing (20% of data)\n",
    "y_train: Target labels for training\n",
    "y_test: Target labels for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ab26fc-8d99-4dd8-a9ee-d758d50076b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 226602, 1: 378})\n",
      "After SMOTE: Counter({0: 226602, 1: 45320})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Check class distribution before SMOTE\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=42)  # Make fraud cases 20% of total\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"After SMOTE:\", Counter(y_train_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb228f-2129-4f63-94f8-ca318c7f9d1e",
   "metadata": {},
   "source": [
    "Handled Imbalanced Data with SMOTE\n",
    "\n",
    "Why?\n",
    "Fraud cases (Class = 1) are very rare in the dataset.\n",
    "If we train a model as-is, it might ignore fraud cases because they are too few.\n",
    "Solution? We use SMOTE (Synthetic Minority Over-sampling Technique) to increase fraud cases in y_train.\n",
    "\n",
    "Outcome:\n",
    "Before applying SMOTE, you’ll see a huge imbalance.\n",
    "After SMOTE, the fraud cases will increase, making it easier for the model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7b4a2-948e-4da1-8196-42b38c50248f",
   "metadata": {},
   "source": [
    "Now we train 3 models and compare them:\n",
    "\n",
    "Logistic Regression (Baseline Model)\n",
    "Random Forest (More complex, handles imbalances well)\n",
    "XGBoost (Best for fraud detection)\n",
    "\n",
    "Model 1: Logistic Regression (Baseline)\n",
    "\n",
    "Why this model?\n",
    "Simple, fast model.\n",
    "Good starting point for classification.\n",
    "Can show whether the dataset is linearly separable.\n",
    "\n",
    "What to Expect?\n",
    "If accuracy is too high (~99%), that means the model is ignoring fraud cases.\n",
    "We need to check Precision, Recall, and F1-score (not just Accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd92df4c-88bf-4fcc-a353-e61fb33f41a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.9948013956930885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.22      0.82      0.35        95\n",
      "\n",
      "    accuracy                           0.99     56746\n",
      "   macro avg       0.61      0.91      0.67     56746\n",
      "weighted avg       1.00      0.99      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eded822-a489-4930-8743-944cc4628943",
   "metadata": {},
   "source": [
    "Key Observations:\n",
    "\n",
    "Overall Accuracy:\n",
    "The model achieves an impressive overall accuracy of 99.48%. This suggests that the model correctly predicts a high proportion of instances in the dataset.\n",
    "\n",
    "Class Distribution:\n",
    "The support values indicate a significant imbalance in the dataset, with 56,651 instances of Class 0 (likely normal transactions) compared to only 95 instances of Class 1 (fraudulent transactions). This imbalance can impact the model's performance and evaluation metrics.\n",
    "\n",
    "Precision, Recall, and F1-Score for Class 0:\n",
    "\n",
    "For Class 0:\n",
    "Precision: 1.00 (100%) indicates that all predicted normal transactions were actually normal, showing no false positives.\n",
    "Recall: 1.00 (100%) means the model successfully identified all actual normal transactions, indicating perfect sensitivity for this class.\n",
    "F1-Score: 1.00 reflects a perfect balance between precision and recall for Class 0.\n",
    "Precision, Recall, and F1-Score for Class 1:\n",
    "\n",
    "For Class 1:\n",
    "Precision: 0.22 (22%) indicates a high number of false positives, meaning many transactions predicted as fraudulent were actually normal.\n",
    "Recall: 0.82 (82%) shows that the model successfully identifies a significant majority of actual fraudulent transactions, but still misses some.\n",
    "F1-Score: 0.35 indicates poor overall performance for Class 1, highlighting the challenges in accurately predicting this minority class.\n",
    "\n",
    "Macro and Weighted Averages:\n",
    "\n",
    "Macro Average:\n",
    "The macro average precision (0.61), recall (0.91), and F1-score (0.67) indicate that while the model performs well on average, the performance is significantly affected by the imbalance in the classes.\n",
    "\n",
    "Weighted Average:\n",
    "The weighted averages (1.00 precision and 0.99 recall) show that the model is heavily influenced by the performance on Class 0, which is the majority class.\n",
    "\n",
    "Potential Issues:\n",
    "The model's high accuracy is somewhat misleading due to the class imbalance. While it performs well on Class 0, its performance on Class 1 is inadequate, suggesting that additional techniques (e.g., resampling, using different evaluation metrics, or employing more sophisticated models) may be needed to improve the detection of fraudulent transactions.\n",
    "\n",
    "Summary\n",
    "The logistic regression model demonstrates high accuracy primarily driven by its performance on the majority class (Class 0). However, its poor precision and F1-score for the minority class (Class 1) reveal significant limitations in detecting fraud, highlighting the need for strategies to address class imbalance and improve overall classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ef031-da46-48dc-bc8e-aaa101923c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52cdf03-71ed-4ae9-8870-69ff50ec033f",
   "metadata": {},
   "source": [
    "Model 2: Random Forest (Better Handling of Imbalance)\n",
    "\n",
    "Why this model?\n",
    "Handles imbalanced data better than Logistic Regression.\n",
    "Works well with non-linear data.\n",
    "\n",
    "What to Expect?\n",
    "Higher Recall than Logistic Regression.\n",
    "Less bias toward non-fraud transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad64a25b-ab84-49d5-8892-d3608fd5ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Accuracy: 0.9994713283755683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.91      0.76      0.83        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.96      0.88      0.91     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Random Forest Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8479967-60f9-4cd6-bb91-9b8d2585ad00",
   "metadata": {},
   "source": [
    "Overall Accuracy:\n",
    "The model achieves a very high accuracy of 99.95%, indicating it predicts a vast majority of instances correctly.\n",
    "\n",
    "Class Distribution:\n",
    "Similar to the logistic regression results, the class distribution is imbalanced, with 56,651 instances of Class 0 (normal transactions) and only 95 instances of Class 1 (fraudulent transactions).\n",
    "\n",
    "Precision, Recall, and F1-Score for Class 0:\n",
    "\n",
    "For Class 0:\n",
    "Precision: 1.00 (100%) indicates that all predicted normal transactions were indeed normal, showing no false positives.\n",
    "Recall: 1.00 (100%) means the model successfully identified all actual normal transactions, reflecting perfect sensitivity for this class.\n",
    "F1-Score: 1.00 indicates a perfect balance between precision and recall for Class 0.\n",
    "Precision, Recall, and F1-Score for Class 1:\n",
    "\n",
    "For Class 1:\n",
    "Precision: 0.91 (91%) indicates that a high proportion of transactions predicted as fraudulent were actually fraudulent, showing a significant reduction in false positives compared to the logistic regression model.\n",
    "Recall: 0.76 (76%) shows that the model correctly identifies a good percentage of actual fraudulent transactions but still misses some.\n",
    "F1-Score: 0.83 reflects a strong performance for Class 1, indicating a good balance of precision and recall in identifying fraudulent transactions.\n",
    "\n",
    "Macro and Weighted Averages:\n",
    "\n",
    "Macro Average:\n",
    "Macro averages of precision (0.96), recall (0.88), and F1-score (0.91) indicate that the model performs well across both classes, though it still has room for improvement in recall for Class 1.\n",
    "\n",
    "Weighted Average:\n",
    "The weighted averages (1.00 precision, 1.00 recall, and 1.00 F1-score) suggest that the model is excellent at identifying Class 0 and reasonably effective at identifying Class 1, with a strong overall performance.\n",
    "\n",
    "Improvement Over Logistic Regression:\n",
    "Compared to the logistic regression results, the Random Forest model shows significant improvements in precision, recall, and F1-score for Class 1. This suggests that the Random Forest algorithm is better suited for handling the complexities of the feature set and the class imbalance in this dataset.\n",
    "\n",
    "Summary\n",
    "The Random Forest model demonstrates high overall accuracy and performs exceptionally well in identifying normal transactions (Class 0). It also shows substantial improvement in detecting fraudulent transactions (Class 1) compared to logistic regression, with high precision and a reasonable recall. This indicates that Random Forest is a more effective model for this classification problem, particularly in addressing the class imbalance and improving the detection of minority class instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f9eb9-2b01-43c9-83f9-3c0f55a3ef13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9e6839-22ed-492f-b648-6dc31f708829",
   "metadata": {},
   "source": [
    "Model 3: XGBoost (Best for Fraud Detection)\n",
    "\n",
    "Why yhis model?\n",
    "Best model for imbalanced data.\n",
    "Uses boosting to correct errors made in previous iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ce9cc8-7395-4d4d-9c69-12cebc9ad54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryomen/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:51:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results:\n",
      "Accuracy: 0.9993127268882388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.81      0.77      0.79        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.91      0.88      0.89     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train XGBoost\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"XGBoost Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cac004-f763-4cd7-ba08-8f3be35e2467",
   "metadata": {},
   "source": [
    "Overall Accuracy:\n",
    "The model achieves a very high accuracy of 99.93%, indicating that it accurately predicts the vast majority of instances in the dataset.\n",
    "\n",
    "Class Distribution:\n",
    "Similar to the previous models, the class distribution is imbalanced, with 56,651 instances of Class 0 (normal transactions) and only 95 instances of Class 1 (fraudulent transactions).\n",
    "\n",
    "Precision, Recall, and F1-Score for Class 0:\n",
    "\n",
    "or Class 0:\n",
    "Precision: 1.00 (100%) indicates that all predicted normal transactions were indeed normal, reflecting no false positives.\n",
    "Recall: 1.00 (100%) means that the model successfully identified all actual normal transactions, showcasing perfect sensitivity for this class.\n",
    "F1-Score: 1.00 indicates a perfect balance between precision and recall for Class 0.\n",
    "Precision, Recall, and F1-Score for Class 1:\n",
    "\n",
    "For Class 1:\n",
    "Precision: 0.81 (81%) indicates that a good proportion of transactions predicted as fraudulent were indeed fraudulent, though there are still some false positives.\n",
    "Recall: 0.77 (77%) shows that the model correctly identifies a significant number of actual fraudulent transactions, but it misses some.\n",
    "F1-Score: 0.79 reflects a reasonable balance of precision and recall for detecting fraudulent transactions.\n",
    "\n",
    "Macro and Weighted Averages:\n",
    "\n",
    "Macro Average:\n",
    "Macro averages of precision (0.91), recall (0.88), and F1-score (0.89) indicate that the model performs well across both classes, though it still has some room for improvement in identifying Class 1.\n",
    "\n",
    "Weighted Average:\n",
    "The weighted averages (1.00 precision, 1.00 recall, and 1.00 F1-score) suggest that the model is excellent at identifying Class 0 and reasonably effective at identifying Class 1, with strong overall performance.\n",
    "\n",
    "Comparison with Other Models:\n",
    "Compared to the Random Forest results, the XGBoost model shows slightly lower precision (81% vs. 91%) for Class 1, while still maintaining a good recall (77%). This indicates that while XGBoost is effective, it may not capture fraudulent transactions as accurately as Random Forest.\n",
    "Overall, both models perform well, but the Random Forest model appears to provide a better balance between precision and recall for the minority class.\n",
    "\n",
    "Summary\n",
    "The XGBoost model demonstrates high overall accuracy and performs exceptionally well in identifying normal transactions (Class 0). It also shows good performance in detecting fraudulent transactions (Class 1), although not as strong as Random Forest. The results highlight XGBoost's effectiveness while also indicating that there is room for improvement in detecting the minority class, making it important to consider model selection and potential enhancements for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70c0c3-01bb-40d3-bbe9-1db938dd72a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df10aa44-1ae2-4aac-87a6-c7fb74403f10",
   "metadata": {},
   "source": [
    "Comparison of all Models\n",
    "\n",
    "Logistic Regression:\n",
    "Accuracy: 99.48%\n",
    "Class 0 Precision: 100%\n",
    "Class 1 Precision: 22%\n",
    "Class 1 Recall: 82%\n",
    "F1 Score for Class 1: 35%\n",
    "Insights: While it has high accuracy, it struggles significantly with the minority class, yielding a very low precision for Class 1.\n",
    "\n",
    "Random Forest:\n",
    "Accuracy: 99.95%\n",
    "Class 0 Precision: 100%\n",
    "Class 1 Precision: 91%\n",
    "Class 1 Recall: 76%\n",
    "F1 Score for Class 1: 83%\n",
    "Insights: Offers a strong performance for Class 1, with high precision and a good recall. It effectively balances performance across both classes.\n",
    "\n",
    "XGBoost:\n",
    "Accuracy: 99.93%\n",
    "Class 0 Precision: 100%\n",
    "Class 1 Precision: 81%\n",
    "Class 1 Recall: 77%\n",
    "F1 Score for Class 1: 79%\n",
    "Insights: Provides solid performance for Class 1, though slightly lower in precision than Random Forest. It captures many fraudulent transactions but still has room for improvement.\n",
    "\n",
    "Summary of Model Performance\n",
    "Logistic Regression is not effective for identifying the minority class despite high accuracy due to class imbalance.\n",
    "Random Forest shows the best balance of precision and recall for Class 1, making it the most robust model in this context.\n",
    "XGBoost performs well but trails slightly behind Random Forest in precision for Class 1.\n",
    "\n",
    "Recommendations for Improvement\n",
    "\n",
    "Address Class Imbalance:\n",
    "Resampling Techniques: Use oversampling (e.g., SMOTE) to generate synthetic samples of the minority class or undersampling to reduce the majority class.\n",
    "Class Weighting: Adjust the class weights in the model to penalize misclassifications of the minority class more heavily.\n",
    "\n",
    "Feature Engineering:\n",
    "Create New Features: Explore additional features that may improve the model’s ability to distinguish between classes (e.g., transaction patterns, time of day).\n",
    "\n",
    "Feature Selection: Use techniques like Recursive Feature Elimination (RFE) or feature importance from Random Forest/XGBoost to select the most predictive features.\n",
    "\n",
    "Hyperparameter Tuning:\n",
    "Perform grid search or randomized search for hyperparameter optimization on Random Forest and XGBoost to enhance their performance.\n",
    "\n",
    "Ensemble Methods:\n",
    "Consider combining different models (e.g., using stacking or blending) to leverage the strengths of each model and improve overall classification performance.\n",
    "\n",
    "Threshold Adjustment:\n",
    "Adjust the decision threshold for Class 1 predictions to balance precision and recall better, especially if the cost of false negatives is high.\n",
    "\n",
    "Cross-Validation:\n",
    "Implement k-fold cross-validation to ensure model robustness and generalization across different subsets of the data.\n",
    "Advanced Techniques:\n",
    "Explore advanced algorithms like Gradient Boosting Machines (GBM), LightGBM, or neural networks, which may capture complex relationships in the data better.\n",
    "\n",
    "Conclusion\n",
    "While Random Forest currently offers the best balance for this classification task, applying the above strategies can enhance the detection of fraudulent transactions, improving model performance and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0012f1d-823c-4fc3-beb6-b2f2aa48f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_tuned = RandomizedSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "rf_tuned.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
